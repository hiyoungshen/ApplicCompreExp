{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir('../input/cat-and-dog/training_set/training_set/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tensorflow version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本地图片的位置\n",
    "# '../input/dc_2000/train/*/*.jpg'\n",
    "\n",
    "train_image_path = glob.glob('../input/cat-and-dog/training_set/training_set/*/*.jpg')\n",
    "\n",
    "len(train_image_path)# kaggle上8005张图片\n",
    "train_image_path[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_image_path) # 打乱路径, 前面几千张全是狗， 后面的全是猫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本地数据集读取标签\n",
    "# train_image_label = [int(path.split('input/dc_2000/train/')[0].split('\\\\')[1].split('.')[0] == 'cat') for path in train_image_path]\n",
    "\n",
    "# kaggle上的数据集读取标签\n",
    "# ../input/cat-and-dog/training_set/training_set/cats/cat.2853.jpg\n",
    "train_image_label = [int(path.split('/training_set/training_set/')[1].split('/')[1].split('.')[0] == 'cat') for path in train_image_path]\n",
    "train_image_label[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看读取到的图片是否正确\n",
    "# image = tf.io.read_file(train_image_path[0])\n",
    "# image = tf.image.decode_jpeg(image, channels=3)\n",
    "# print(image.shape)\n",
    "# plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_image(path, label):\n",
    "    '''\n",
    "    func:根据路径载入图像和label\n",
    "    '''\n",
    "\n",
    "\n",
    "    image = tf.io.read_file(path)   # 根据文件路径读取文件\n",
    "    image = tf.image.decode_jpeg(image,channels=3) # jpg解码\n",
    "    image = tf.image.resize(image, [256, 256]) # 统一大小\n",
    "    \n",
    "#    image = tf.image.random_crop(image, [256, 256, 3])\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, 0.5)\n",
    "    image = tf.image.random_contrast(image, 0, 1)\n",
    "    image = tf.cast(image, tf.float32)  # 转换数据类型\n",
    "    image = image/255   # 统一数据范围\n",
    "\n",
    "    label = tf.reshape(label, (1,)) # reshape成(num,)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.image.convert_image_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_ds = tf.data.Dataset.from_tensor_slices((train_image_path, train_image_label)) # load数据集\n",
    "# train_image_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据计算机的特征，自动的使用并行运算\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "# AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理\n",
    "train_image_ds = train_image_ds.map(load_preprocess_image, num_parallel_calls=AUTOTUNE) # 载入图像\n",
    "# print(train_image_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img, label in train_image_ds.take(1):\n",
    "#     plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定batch\n",
    "BATCH_SIZE = 32\n",
    "train_count = len(train_image_path) # 训练数据集的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设立batch, train_image_ds是一个可迭代对象\n",
    "train_image_ds = train_image_ds.shuffle(500).batch(BATCH_SIZE)\n",
    "train_image_ds = train_image_ds.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs,labels=next(iter(train_image_ds))\n",
    "# imgs.shape\n",
    "# imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_image_path = glob.glob('../input/dc_2000/train/*/*.jpg')\n",
    "# train_image_label = [int(path.split('input/dc_2000/train/')[0].split('\\\\')[1].split('.')[0] == 'cat') for path in train_image_path]\n",
    "# test_image_path = glob.glob('../input/dc_2000/test/*/*.jpg')\n",
    "# test_image_label = [int(path.split('input/dc_2000/train/')[0].split('\\\\')[0].split('.')[0] == 'cat') for path in test_image_path]\n",
    "\n",
    "# train_image_path = glob.glob('../input/cat-and-dog/training_set/training_set/*/*.jpg')\n",
    "test_image_path = glob.glob('../input/cat-and-dog/test_set/test_set/*/*.jpg')\n",
    "# train_image_label = [int(path.split('/training_set/training_set/')[1].split('/')[1].split('.')[0] == 'cat') for path in train_image_path]\n",
    "test_image_label = [int(path.split('/test_set/test_set/')[1].split('/')[1].split('.')[0] == 'cat') for path in test_image_path]\n",
    "\n",
    "# 载入测试图片\n",
    "test_image_ds = tf.data.Dataset.from_tensor_slices((test_image_path, test_image_label))\n",
    "test_image_ds = test_image_ds.map(load_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "test_image_ds = test_image_ds.batch(BATCH_SIZE)\n",
    "test_image_ds = test_image_ds.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), input_shape=(256, 256, 3), activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(1024, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    # tf.keras.layers.Conv2D(1024, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "odel: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param \\#   \n",
    "=================================================================\n",
    "conv2d (Conv2D)              (None, 254, 254, 64)      1792      \n",
    "_________________________________________________________________\n",
    "max_pooling2d (MaxPooling2D) (None, 127, 127, 64)      0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 125, 125, 128)     73856     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 128)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 60, 60, 256)       295168    \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 256)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
    "_________________________________________________________________\n",
    "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 12, 12, 1024)      4719616   \n",
    "_________________________________________________________________\n",
    "global_average_pooling2d (Gl (None, 1024)              0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 256)               262400    \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 1)                 257       \n",
    "=================================================================\n",
    "Total params: 6,533,249\n",
    "Trainable params: 6,533,249\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.losses.binary_crossentropy([0.,0.,1.,1.], [1.,1.,1.,1.])#二元交叉熵定义loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [https://www.jianshu.com/p/aebcaf8af76e]\n",
    "# 使用Adam优化, 具体一些的对Adam的解释可以看上面的博客\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss_avg = tf.keras.metrics.Mean('train_loss') # \n",
    "train_accuracy = tf.keras.metrics.Accuracy() # 计算正确率\n",
    "\n",
    "epoch_loss_avg_test = tf.keras.metrics.Mean('test_loss')\n",
    "test_accuracy = tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_accuracy([1,0,1], [1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, images, labels):\n",
    "    \"\"\"\n",
    "    func:训练集求梯度\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as t:\n",
    "        pred = model(images) # 使用模型预测结果\n",
    "        loss_step = tf.keras.losses.BinaryCrossentropy(from_logits=True)(labels, pred) # 计算损失值\n",
    "    \n",
    "    grads = t.gradient(loss_step, model.trainable_variables) #计算dloss/d(参数)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables)) #根据dloss/d(variable)进行优化\n",
    "\n",
    "    epoch_loss_avg(loss_step)# 计算loss的均值\n",
    "    train_accuracy(labels, tf.cast(pred>0, tf.int32))# 计算精确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, images, labels):\n",
    "    pred = model(images, training=False)\n",
    "    loss_step = tf.keras.losses.BinaryCrossentropy(from_logits=True)(labels, pred)\n",
    "    epoch_loss_avg_test(loss_step)\n",
    "    test_accuracy(labels, tf.cast(pred>0, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_results = []\n",
    "train_acc_results = []\n",
    "\n",
    "test_loss_results = []\n",
    "test_acc_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "#     print(train_image_ds)\n",
    "    for imgs_, labels_ in train_image_ds:\n",
    "        train_step(model, imgs_, labels_)\n",
    "        print('.', end='')\n",
    "    print()\n",
    "    \n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_acc_results.append(train_accuracy.result())\n",
    "    \n",
    "    \n",
    "    for imgs_, labels_ in test_image_ds:\n",
    "        test_step(model, imgs_, labels_)\n",
    "        \n",
    "    test_loss_results.append(epoch_loss_avg_test.result())\n",
    "    test_acc_results.append(test_accuracy.result())\n",
    "    \n",
    "    print('Epoch:{}: loss: {:.3f}, accuracy: {:.3f}, test_loss: {:.3f}, test_accuracy: {:.3f}'.format(\n",
    "        epoch + 1,\n",
    "        epoch_loss_avg.result(),\n",
    "        train_accuracy.result(),\n",
    "        epoch_loss_avg_test.result(),\n",
    "        test_accuracy.result()\n",
    "    ))\n",
    "    \n",
    "    epoch_loss_avg.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    epoch_loss_avg_test.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:1: loss: 0.690, accuracy: 0.516, test_loss: 0.684, test_accuracy: 0.545\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:2: loss: 0.683, accuracy: 0.540, test_loss: 0.679, test_accuracy: 0.551\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:3: loss: 0.681, accuracy: 0.547, test_loss: 0.678, test_accuracy: 0.571\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:4: loss: 0.672, accuracy: 0.573, test_loss: 0.674, test_accuracy: 0.558\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:5: loss: 0.669, accuracy: 0.572, test_loss: 0.669, test_accuracy: 0.559\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:6: loss: 0.661, accuracy: 0.589, test_loss: 0.656, test_accuracy: 0.597\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:7: loss: 0.657, accuracy: 0.595, test_loss: 0.647, test_accuracy: 0.609\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:8: loss: 0.647, accuracy: 0.612, test_loss: 0.650, test_accuracy: 0.607\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:9: loss: 0.637, accuracy: 0.625, test_loss: 0.639, test_accuracy: 0.634\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:10: loss: 0.634, accuracy: 0.619, test_loss: 0.632, test_accuracy: 0.627\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:11: loss: 0.620, accuracy: 0.644, test_loss: 0.613, test_accuracy: 0.662\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:12: loss: 0.608, accuracy: 0.656, test_loss: 0.616, test_accuracy: 0.645\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:13: loss: 0.607, accuracy: 0.655, test_loss: 0.599, test_accuracy: 0.666\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:14: loss: 0.599, accuracy: 0.666, test_loss: 0.592, test_accuracy: 0.674\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:15: loss: 0.595, accuracy: 0.672, test_loss: 0.602, test_accuracy: 0.663\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:16: loss: 0.579, accuracy: 0.688, test_loss: 0.578, test_accuracy: 0.683\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:17: loss: 0.582, accuracy: 0.687, test_loss: 0.567, test_accuracy: 0.699\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:18: loss: 0.581, accuracy: 0.679, test_loss: 0.575, test_accuracy: 0.701\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:19: loss: 0.572, accuracy: 0.692, test_loss: 0.572, test_accuracy: 0.694\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:20: loss: 0.559, accuracy: 0.704, test_loss: 0.559, test_accuracy: 0.705\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:21: loss: 0.547, accuracy: 0.711, test_loss: 0.561, test_accuracy: 0.703\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:22: loss: 0.558, accuracy: 0.707, test_loss: 0.568, test_accuracy: 0.692\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:23: loss: 0.534, accuracy: 0.724, test_loss: 0.550, test_accuracy: 0.726\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:24: loss: 0.536, accuracy: 0.719, test_loss: 0.536, test_accuracy: 0.728\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:25: loss: 0.523, accuracy: 0.729, test_loss: 0.544, test_accuracy: 0.724\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:26: loss: 0.516, accuracy: 0.736, test_loss: 0.536, test_accuracy: 0.716\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:27: loss: 0.512, accuracy: 0.741, test_loss: 0.545, test_accuracy: 0.719\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:28: loss: 0.500, accuracy: 0.740, test_loss: 0.492, test_accuracy: 0.759\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:29: loss: 0.483, accuracy: 0.759, test_loss: 0.505, test_accuracy: 0.738\n",
    "...........................................................................................................................................................................................................................................................\n",
    "Epoch:30: loss: 0.481, accuracy: 0.755, test_loss: 0.487, test_accuracy: 0.750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_acc_results))\n",
    "print(len(test_acc_results))\n",
    "plt.plot(range(1,num_epochs+1),train_acc_results,label='train_accuracy')\n",
    "plt.plot(range(1,num_epochs+1),test_acc_results,label='test_accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,num_epochs+1),train_loss_results,label='train_loss')\n",
    "plt.plot(range(1,num_epochs+1),test_loss_results,label='test_loss')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2]",
   "language": "python",
   "name": "conda-env-tf2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
