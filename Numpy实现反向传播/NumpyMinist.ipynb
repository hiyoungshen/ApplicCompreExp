{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def tanh(x):\n",
    "    s1 = np.exp(x) - np.exp(-x)\n",
    "    s2 = np.exp(x) + np.exp(-x)\n",
    "    s = s1 / s2\n",
    "    return s\n",
    "\n",
    "# sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "# sigmoid的一阶导数\n",
    "def Dsigmoid(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 标签one-hot处理\n",
    "# 没一行代表一个样本的一个one-hot编码\n",
    "# inputs: targets, 维度为n，targets[i]代表一个样本的标签，\n",
    "# num: num==n\n",
    "def onehot(targets, num):\n",
    "    result = np.zeros((num, 10))\n",
    "    for i in range(num):\n",
    "        result[i][targets[i]] = 1\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class NN(object):\n",
    "    # lay0, lay1, lay2, lay3, batch_size\n",
    "    # lay1是输入向量的维度，lay3是输出向量的维度\n",
    "    def __init__(self, l0, l1, l2, l3, batch_size=6):\n",
    "        self.lr = 0.4\n",
    "        self.batch_size = batch_size\n",
    "        # [l0,l1]\n",
    "        self.W1 = np.random.randn(l0, l1) * 0.01\n",
    "        self.b1 = np.random.randn(l1) * 0.01\n",
    "        # [l1, l2]\n",
    "        self.W2 = np.random.randn(l1, l2) * 0.01\n",
    "        self.b2 = np.random.randn(l2) * 0.01\n",
    "        # [l2, l3]\n",
    "        self.W3 = np.random.randn(l2, l3) * 0.01\n",
    "        self.b3 = np.random.randn(l3) * 0.01\n",
    " \n",
    "    # 前向传播\n",
    "    # X: [n, l0]\n",
    "    # y: [n, 10]\n",
    "    def forward(self, X, y):\n",
    "        # [n, l0]\n",
    "        self.X = X                                           \n",
    "        self.z1 = np.dot(X, self.W1) + self.b1               # [n, l0] x [l0, l1], 等于中间层层数\n",
    "        self.a1 = sigmoid(self.z1)                           # [n, l1]\n",
    " \n",
    "        # self.z2 = np.dot(self.a1, self.W2) + self.b2         # m x 30\n",
    "        # self.a2 = sigmoid(self.z2)                           # m x 30\n",
    " \n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2  # [n,l1]*[l1,l2]\n",
    "        self.a2 = sigmoid(self.z2)                    # [n, l2]\n",
    " \n",
    "        self.z3 = np.dot(self.a2, self.W3) + self.b3  # [n, l2] x [l2, l3]     \n",
    "        self.a3 = sigmoid(self.z3)                    # [n, l3]                          \n",
    " \n",
    "        loss = np.sum((self.a3 - y) * (self.a3 - y)) / 6     # 1\n",
    "        \n",
    "        # f(x)=sigmod(g(x))\n",
    "        # d(f(x))/d(x)=d(f(x))/d(g(x))*d(g(x))/d(x)\n",
    "        self.d3 = (self.a3 - y) * Dsigmoid(self.z3)          # [n, l3]\n",
    "        return loss, self.a3\n",
    " \n",
    "    # 反向传播\n",
    "    def backward(self):\n",
    "        dW3 = np.dot(self.a2.T, self.d3) / self.batch_size          # [l2, n] x [n, l3] / 6 = [l2, l3]\n",
    "        db3 = np.sum(self.d3, axis=0) / self.batch_size             # [n, l3] -> [l3]               \n",
    " \n",
    "        d2 = np.dot(self.d3, self.W3.T) * Dsigmoid(self.z2)         # [n, l3] x [l3, l2] x [n, l2]\n",
    "        dW2 = np.dot(self.a1.T, d2) / self.batch_size               # [l1, n] x [n, l2] = [l1, l2]\n",
    "        db2 = np.sum(d2, axis=0) / self.batch_size                  # [n, l2] -> [l2]\n",
    " \n",
    "        d1 = np.dot(d2, self.W2.T) * Dsigmoid(self.z1)              # [n, l2] x [l2, l1] x [n ,l1] = [n, l1]\n",
    "        dW1 = np.dot(self.X.T, d1) / self.batch_size                # [l0, n] x [n, l1] = [l0, l1]        \n",
    "        db1 = np.sum(d1, axis=0) / self.batch_size                  # [n, l1] -> [l1]\n",
    " \n",
    "        self.W3 -= self.lr * dW3\n",
    "        self.b3 -= self.lr * db3\n",
    "        self.W2 -= self.lr * dW2\n",
    "        self.b2 -= self.lr * db2\n",
    "        self.W1 -= self.lr * dW1\n",
    "        self.b1 -= self.lr * db1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "def train(train_data):\n",
    "    \n",
    "    nn = NN(784, 200, 30, 10)\n",
    "    print(f\"{datetime.now()} Begin training...\")\n",
    "\n",
    "    for epoch in tqdm(range(10)):\n",
    "        loss_sum=0\n",
    "        num_pic=0\n",
    "        \n",
    "        for i in range(0, 60000, nn.batch_size):\n",
    "            X = train_data.data[i:i+nn.batch_size]\n",
    "            Y = train_data.targets[i:i+nn.batch_size]\n",
    "            loss, _ = nn.forward(X, Y)\n",
    "            loss_sum += loss\n",
    "            num_pic += 1\n",
    "            # print(\"epoch:\", epoch, \"-\", i, \":\", \"{:.3f}\".format(loss) )\n",
    "            nn.backward()\n",
    "            \n",
    "        tqdm.write(\n",
    "            f\"Epoch: {epoch} Train loss: {loss_sum/num_pic}\",\n",
    "            end=\" \",\n",
    "        )\n",
    "        writer.add_scalar(\"Loss/train\", loss_sum/num_pic, epoch)\n",
    "        \n",
    "        np.savez(\"data.npz\", w1=nn.W1, b1=nn.b1, w2=nn.W2, b2=nn.b2, w3=nn.W3, b3=nn.b3)\n",
    "    writer.close()\n",
    "    print(f\"{datetime.now()} End training...\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def test(test_data):\n",
    "    r = np.load(\"data.npz\")\n",
    "    nn = NN(784, 200, 30, 10)\n",
    "    nn.W1 = r[\"w1\"]\n",
    "    nn.b1 = r[\"b1\"]\n",
    "    nn.W2 = r[\"w2\"]\n",
    "    nn.b2 = r[\"b2\"]\n",
    "    nn.W3 = r[\"w3\"]\n",
    "    nn.b3 = r[\"b3\"]\n",
    " \n",
    " \n",
    "    _, result = nn.forward(test_data.data, test_data.targets1)\n",
    "    result = np.argmax(result, axis=1)\n",
    "    # print(result)\n",
    "    precison = np.sum(result==test_data.targets) / 10000\n",
    "    print(\"Precison:\", precison)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "if __name__ == '__main__':\n",
    " \n",
    "    # Mnist手写数字集\n",
    "    train_data = torchvision.datasets.MNIST(root='data/', train=True, download=True)\n",
    "    test_data = torchvision.datasets.MNIST(root='data/', train=False)\n",
    "    train_data.data = train_data.data.numpy()         # [60000,28,28]\n",
    "    train_data.targets = train_data.targets.numpy()   # [60000]\n",
    "    test_data.data = test_data.data.numpy()           # [10000,28,28]\n",
    "    test_data.targets = test_data.targets.numpy()     # [10000]\n",
    " \n",
    "    # 输入向量处理\n",
    "    train_data.data = train_data.data.reshape(60000, 28 * 28) / 255.  # (60000, 784)\n",
    "    test_data.data = test_data.data.reshape(10000, 28 * 28) / 255.\n",
    " \n",
    "    # 标签one-hot处理\n",
    "    train_data.targets = onehot(train_data.targets, 60000) # (60000, 10)\n",
    "    test_data.targets1 = onehot(test_data.targets, 10000)  # (10000, 10)\n",
    " \n",
    "    train(train_data)\n",
    "    test(test_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-09-23 10:43:55.504905 Begin training...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 10%|█         | 1/10 [00:08<01:14,  8.23s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Train loss: 0.8875768293275492 "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 20%|██        | 2/10 [00:16<01:05,  8.24s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1 Train loss: 0.47149937666761277 "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 30%|███       | 3/10 [00:24<00:57,  8.27s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 2 Train loss: 0.13782746233950394 "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 40%|████      | 4/10 [00:32<00:49,  8.22s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 3 Train loss: 0.09607324276702973 "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 50%|█████     | 5/10 [00:41<00:41,  8.21s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 4 Train loss: 0.07463461998733435 "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 60%|██████    | 6/10 [00:48<00:32,  8.06s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 5 Train loss: 0.060987298314839004 "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 70%|███████   | 7/10 [00:56<00:23,  7.96s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 6 Train loss: 0.05154206474473889 "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 80%|████████  | 8/10 [01:04<00:15,  7.89s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 7 Train loss: 0.04446003767459459 "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 90%|█████████ | 9/10 [01:12<00:07,  7.85s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 8 Train loss: 0.03892860199496097 "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10/10 [01:19<00:00,  8.00s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 9 Train loss: 0.034385237049216894 2021-09-23 10:45:15.482111 End training...\n",
      "Precison: 0.9723\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "test(test_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precison: 0.9723\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "4e2dd49795a22e4b0576058242cdc48a6669c7f26dd07ce146ad215d54a791f9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}